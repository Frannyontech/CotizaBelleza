# MÃ³dulo de Scraping - CotizaBelleza

MÃ³dulo base para scraping de sitios web de belleza usando requests + BeautifulSoup.

## ğŸš€ CaracterÃ­sticas

- **Scraping inteligente** con requests y BeautifulSoup
- **ExtracciÃ³n de dataLayer** para obtener informaciÃ³n detallada de productos
- **Manejo de delays** para ser respetuoso con los servidores
- **Logging completo** para debugging y monitoreo
- **ExportaciÃ³n mÃºltiple** (JSON, CSV)
- **ConfiguraciÃ³n flexible** para diferentes sitios web

## ğŸ“ Estructura del Proyecto

```
scraper/
â”œâ”€â”€ __init__.py                 # MÃ³dulo principal
â”œâ”€â”€ config.py                   # Configuraciones y constantes
â”œâ”€â”€ utils.py                    # Utilidades y funciones auxiliares
â”œâ”€â”€ unify_products.py          # Script de unificaciÃ³n de datos
â”œâ”€â”€ README.md                  # Esta documentaciÃ³n
â”œâ”€â”€ data/                      # Datos extraÃ­dos
â”‚   â”œâ”€â”€ dbs_productos.json     # Productos DBS
â”‚   â”œâ”€â”€ preunic_productos.json # Productos Preunic
â”‚   â””â”€â”€ maicao_productos.json  # Productos Maicao
â””â”€â”€ scrapers/
    â”œâ”€â”€ __init__.py               # SubmÃ³dulo scrapers
    â”œâ”€â”€ dbs_selenium_scraper.py   # Scraper DBS (Selenium)
    â”œâ”€â”€ preunic_selenium_scraper.py # Scraper Preunic (Selenium)
    â””â”€â”€ maicao_selenium_scraper.py  # Scraper Maicao (Selenium)
```

## ğŸ› ï¸ InstalaciÃ³n

### Dependencias

```bash
pip install requests beautifulsoup4 selenium
```

### Dependencias del sistema

```bash
# ChromeDriver para Selenium (debe estar en PATH)
# O usar webdriver-manager para instalaciÃ³n automÃ¡tica:
pip install webdriver-manager
```

### Dependencias opcionales

```bash
pip install pandas openpyxl  # Para exportaciÃ³n a Excel
```

## ğŸ“– Uso BÃ¡sico

### Scraper de Maicao (Selenium con PaginaciÃ³n)

```python
from scraper.scrapers.maicao_selenium_scraper import scrape_maicao_all_categories

# Scraping completo de todas las categorÃ­as
productos = scrape_maicao_all_categories(headless=True)

# Scraping limitado (solo primeras pÃ¡ginas para pruebas)
productos = scrape_maicao_all_categories(headless=True, max_pages_per_category=3)

# Ejecutar directamente
cd scraper/scrapers
python maicao_selenium_scraper.py
```

### Scraping de DBS

```python
from scraper.scrapers.dbs_selenium_scraper import scrapear_pagina_dbs

# Scraping de una pÃ¡gina de categorÃ­a
url = "https://www.dbs.cl/maquillaje"
productos = scrapear_pagina_dbs(url)

# Mostrar resultados
for producto in productos:
    print(f"{producto.nombre} - ${producto.precio}")
```

### Scraping de mÃºltiples pÃ¡ginas

```python
from scraper.scrapers.dbs_scraper import scrapear_catalogo_dbs

# URLs de categorÃ­as
urls = [
    "https://www.dbs.cl/maquillaje",
    "https://www.dbs.cl/skincare",
]

# Scraping con delay entre requests
productos = scrapear_catalogo_dbs(urls, delay=2.0)

print(f"Total de productos: {len(productos)}")
```

### Uso con logging

```python
from scraper.utils import setup_logging, save_to_json, generate_filename

# Configurar logging
logger = setup_logging('mi_scraper')

# Scraping
productos = scrapear_pagina_dbs(url)

# Guardar resultados
if productos:
    filename = generate_filename("productos_dbs", "json")
    save_to_json([p.to_dict() for p in productos], filename)
    logger.info(f"Datos guardados en {filename}")
```

## ğŸ”§ ConfiguraciÃ³n

### ConfiguraciÃ³n de delays

```python
from scraper.config import DELAY_CONFIG

# Modificar delays
DELAY_CONFIG['min_delay'] = 1.5
DELAY_CONFIG['max_delay'] = 3.0
DELAY_CONFIG['random_delay'] = True
```

### ConfiguraciÃ³n de headers

```python
from scraper.config import REQUEST_CONFIG

# Agregar headers personalizados
REQUEST_CONFIG['headers']['User-Agent'] = 'Mi Bot/1.0'
```

## ğŸ“Š Clase DBSProduct

Cada producto extraÃ­do se representa como un objeto `DBSProduct`:

```python
producto = DBSProduct(
    nombre="Base de Maquillaje",
    marca="L'OrÃ©al",
    precio=15990.0,
    categoria="maquillaje",
    stock=True,
    estrellas=4.5,
    url="https://www.dbs.cl/producto/123",
    imagen="https://www.dbs.cl/imagen.jpg"
)

# Convertir a diccionario
datos = producto.to_dict()
```

### Atributos disponibles

- `nombre`: Nombre del producto
- `marca`: Marca del producto
- `precio`: Precio numÃ©rico
- `categoria`: CategorÃ­a del producto
- `stock`: Disponibilidad (True/False)
- `estrellas`: Rating del producto (0.0 - 5.0)
- `url`: URL del producto
- `imagen`: URL de la imagen

## ğŸ” ExtracciÃ³n de dataLayer

El scraper extrae informaciÃ³n del atributo `onclick` que contiene dataLayer:

```javascript
// Ejemplo de dataLayer en onclick
onclick="dataLayer.push({
    'product_name': 'Base de Maquillaje',
    'product_brand': 'L\'OrÃ©al',
    'product_price': '15990',
    'product_category': 'maquillaje',
    'product_availability': 'in stock',
    'product_rating': '4.5'
})"
```

## ğŸ“ˆ Funciones de Utilidad

### Limpieza de texto

```python
from scraper.utils import clean_text

texto_limpio = clean_text("  Texto   con   espacios  ")
# Resultado: "Texto con espacios"
```

### ExtracciÃ³n de precios

```python
from scraper.utils import extract_price

precio = extract_price("$15.990")
# Resultado: 15990.0
```

### ExportaciÃ³n de datos

```python
from scraper.utils import save_to_json, save_to_csv

# Guardar en JSON
save_to_json(productos_dict, "productos.json")

# Guardar en CSV
save_to_csv(productos_dict, "productos.csv")
```

## ğŸš¨ Consideraciones Ã‰ticas

### Delays y Rate Limiting

- **Delay mÃ­nimo**: 1 segundo entre requests
- **Delay recomendado**: 2-3 segundos
- **Delay aleatorio**: Evita patrones detectables

### Headers apropiados

- **User-Agent**: Identifica el bot
- **Accept**: Headers estÃ¡ndar del navegador
- **Referer**: Simula navegaciÃ³n real

### Respeto a robots.txt

```python
# Verificar robots.txt antes de scraping
import requests
from urllib.robotparser import RobotFileParser

rp = RobotFileParser()
rp.set_url("https://www.dbs.cl/robots.txt")
rp.read()

if rp.can_fetch("*", "/maquillaje"):
    # Proceder con scraping
    productos = scrapear_pagina_dbs(url)
```

## ğŸ› Debugging

### Logging detallado

```python
from scraper.utils import setup_logging

logger = setup_logging('debug_scraper')
logger.setLevel('DEBUG')

# El scraper mostrarÃ¡ informaciÃ³n detallada
productos = scrapear_pagina_dbs(url)
```

### Verificar respuesta HTTP

```python
from scraper.scrapers.dbs_scraper import DBSScraper

scraper = DBSScraper()
soup = scraper._get_page(url)

if soup:
    print("PÃ¡gina cargada correctamente")
    print(f"TÃ­tulo: {soup.title.string}")
else:
    print("Error al cargar la pÃ¡gina")
```

## ğŸ“ Ejemplos Completos

Ver `example_usage.py` para ejemplos completos de:

1. Scraping de una pÃ¡gina
2. Scraping de mÃºltiples pÃ¡ginas
3. Scraping con logging
4. AnÃ¡lisis de precios
5. ExportaciÃ³n de datos

## ğŸ”„ Extensibilidad

### Agregar nuevo scraper

```python
# scraper/scrapers/nuevo_sitio_scraper.py
from .dbs_scraper import DBSScraper

class NuevoSitioScraper(DBSScraper):
    def __init__(self):
        super().__init__()
        self.base_url = "https://www.nuevo-sitio.cl"
    
    def scrapear_pagina_nuevo_sitio(self, url):
        # Implementar lÃ³gica especÃ­fica
        pass
```

### Personalizar selectores CSS

```python
# En config.py
CSS_SELECTORS['nuevo_sitio'] = {
    'product_container': '.producto',
    'product_name': '.nombre-producto',
    'product_price': '.precio',
    # ...
}
```

## ğŸª Tiendas Soportadas

| Tienda | Scraper | TecnologÃ­a | CategorÃ­as | Estado |
|--------|---------|------------|------------|--------|
| **DBS** | `dbs_selenium_scraper.py` | Selenium + BeautifulSoup | `maquillaje`, `skincare` | âœ… Funcional |
| **Preunic** | `preunic_selenium_scraper.py` | Selenium + BeautifulSoup | `maquillaje`, `skincare` | âœ… Funcional |
| **Maicao** | `maicao_selenium_scraper.py` | Selenium + PaginaciÃ³n | `maquillaje`, `skincare` | âœ… Funcional |

### CaracterÃ­sticas por Scraper

#### Maicao Scraper
- âœ… **PaginaciÃ³n avanzada** (detecciÃ³n automÃ¡tica de pÃ¡ginas)
- âœ… **ExtracciÃ³n de precios desde detalle** si no se encuentra en lista
- âœ… **Scroll infinito reemplazado** por navegaciÃ³n correcta
- âœ… **Estructura JSON estandarizada** con otras tiendas

#### DBS Scraper
- âœ… **NavegaciÃ³n por pÃ¡ginas** numeradas
- âœ… **DetecciÃ³n automÃ¡tica de total de pÃ¡ginas**
- âœ… **ExtracciÃ³n de imÃ¡genes lazy-loading**

#### Preunic Scraper
- âœ… **Scroll infinito** hasta carga completa
- âœ… **Manejo de productos sin precio**
- âœ… **ExtracciÃ³n de marcas inteligente**

## ğŸ“„ Licencia

Este mÃ³dulo es parte del proyecto CotizaBelleza y estÃ¡ bajo la misma licencia.

## ğŸ¤ Contribuciones

Para contribuir al mÃ³dulo de scraping:

1. Fork el repositorio
2. Crea una rama para tu feature
3. Implementa el scraper para un nuevo sitio
4. Agrega tests y documentaciÃ³n
5. EnvÃ­a un pull request

## ğŸ“ Soporte

Para reportar bugs o solicitar features:

- Abre un issue en GitHub
- Incluye logs y ejemplos de reproducciÃ³n
- Especifica la versiÃ³n del mÃ³dulo 